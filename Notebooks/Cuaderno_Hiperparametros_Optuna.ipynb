{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT8JODGcJNms"
      },
      "source": [
        "# Configuración (importar dependencias, librerías, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDGnBvlKAu2A",
        "outputId": "e25613bb-8360-4101-dc67-dea2a2e1c52c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (0.29.2)\n",
            "Requirement already satisfied: psutil in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
            "Requirement already satisfied: huggingface-hub in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from accelerate) (2.2.2)\n",
            "Requirement already satisfied: pyyaml in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from accelerate) (22.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: jinja2 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: sympy in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: filelock in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
            "Requirement already satisfied: fsspec in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: networkx in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.8.4)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bzwZtebBKy1"
      },
      "outputs": [],
      "source": [
        "# Hiperparámetros\n",
        "#model_checkpoint = 'xlm-roberta-base'\n",
        "# model_checkpoint = 'bert-base-uncased'\n",
        "# model_checkpoint = 'roberta-base'\n",
        "\n",
        "# model_checkpoint = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
        "model_checkpoint = 'PlanTL-GOB-ES/roberta-base-bne'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H96BooZewZ79",
        "outputId": "60e17971-afd2-4178-81a2-bb7f97d3ed0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (4.11.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (4.64.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (0.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (22.0)\n",
            "Requirement already satisfied: torch>=1.13.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.4)\n",
            "Requirement already satisfied: setuptools in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (65.6.3)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (2.19.3)\n",
            "Requirement already satisfied: jinja2 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.0.106)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (2.2.0)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (10.3.2.106)\n",
            "Requirement already satisfied: sympy in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: filelock in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (3.9.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (12.1.105)\n",
            "Requirement already satisfied: networkx in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from torch>=1.13.0->pytorch-lightning) (2.8.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (22.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.13.0->pytorch-lightning) (1.2.1)\n",
            "Requirement already satisfied: idna>=2.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
            "Requirement already satisfied: datasets in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (2.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: filelock in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: multiprocess in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: aiohttp in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from datasets) (3.9.4)\n",
            "Requirement already satisfied: pandas in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
            "Requirement already satisfied: xxhash in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (0.2.0)\n",
            "Requirement already satisfied: contractions in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: pyahocorasick in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
            "Requirement already satisfied: anyascii in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: textblob in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (0.18.0.post0)\n",
            "Requirement already satisfied: nltk>=3.8 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.64.1)\n",
            "Requirement already satisfied: joblib in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2022.7.9)\n",
            "Requirement already satisfied: click in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
            "Requirement already satisfied: optuna in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (3.6.1)\n",
            "Requirement already satisfied: numpy in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: colorlog in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: tqdm in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from optuna) (22.0)\n",
            "Requirement already satisfied: PyYAML in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from optuna) (1.4.39)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: Mako in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/manuelcerrejon/anaconda3/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n"
          ]
        }
      ],
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "# esto hay que ponerlo justo antes de importar para que los experimentos\n",
        "# sean reproducible\n",
        "\n",
        "!pip install pytorch-lightning\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_lightning import seed_everything\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)# Store the average loss after eachepoch so we can plot them.\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\" # See:https://github.com/NVIDIA/tensorflow-determinism#confirmed-current-gpu-specific-sources-of-non-determinism-with-solutions\n",
        "seed_everything(42, workers=True)\n",
        "\n",
        "!pip install transformers datasets\n",
        "!pip install sentencepiece\n",
        "!pip install contractions\n",
        "!pip install textblob\n",
        "!pip install optuna\n",
        "from datasets import Dataset, DatasetDict, load_metric\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
        " TrainingArguments, Trainer, pipeline, EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbYlg_MwAu2C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from pytorch_lightning import seed_everything\n",
        "\n",
        "from datasets import Dataset, DatasetDict, load_metric\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, \\\n",
        " TrainingArguments, Trainer, pipeline, EarlyStoppingCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN_n0chOaNxt",
        "outputId": "263fa943-ebef-488b-a602-e332f2617631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Name: NVIDIA GeForce RTX 4070\n",
            "GPU Capability: 8.9\n",
            "Total GPU Memory: 11.72 GB\n",
            "Free GPU Memory: 11.72 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Verificar si CUDA está disponible\n",
        "if torch.cuda.is_available():\n",
        "    # Obtener el nombre de la GPU\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "\n",
        "    # Obtener la capacidad de la GPU\n",
        "    gpu_capability = torch.cuda.get_device_capability(0)\n",
        "\n",
        "    # Obtener la memoria total y disponible en la GPU\n",
        "    gpu_memory_info = torch.cuda.get_device_properties(0)\n",
        "\n",
        "    print(f\"GPU Name: {gpu_name}\")\n",
        "    print(f\"GPU Capability: {gpu_capability[0]}.{gpu_capability[1]}\")\n",
        "    print(f\"Total GPU Memory: {gpu_memory_info.total_memory / (1024**3):.2f} GB\")\n",
        "    print(f\"Free GPU Memory: {torch.cuda.get_device_properties(0).total_memory / (1024**3) - torch.cuda.memory_allocated() / (1024**3):.2f} GB\")\n",
        "else:\n",
        "    print(\"CUDA not available. Make sure your Jupyter Notebook is running with a GPU kernel.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWEO2KP6qrCw",
        "outputId": "64e4f163-c46b-4802-89ba-959329eb7b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU detected. Currently using: \"NVIDIA GeForce RTX 4070\"\n"
          ]
        }
      ],
      "source": [
        "# Check that pyTorch is identifying the GPU\n",
        "if torch.cuda.device_count() > 0:\n",
        "  print(f'GPU detected. Currently using: \"{torch.cuda.get_device_name(0)}\"')\n",
        "else:\n",
        "  print('Currently using CPU, change the type of the runtime in the \\'runtime\\' tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWlOoSXar61D"
      },
      "source": [
        "# Preparación de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y108FPZhtaV6"
      },
      "source": [
        "## Lectura de los ficheros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgNTbxv4tIZN"
      },
      "outputs": [],
      "source": [
        "# Cargamos los datos de entrenamiento y test\n",
        "import pandas as pd\n",
        "data_path = '/home/manuelcerrejon/TFG/Task 1/Detests/BackTranslation/Datos/'\n",
        "test_path = '/home/manuelcerrejon/TFG/Task 1/Detests/Preprocesing/Datos/'\n",
        "# Los pasamos a dataframes\n",
        "train_df = pd.read_csv(data_path + 'train_detests_df_a1_bt.csv', encoding = 'UTF-8', sep=',')\n",
        "test_df = pd.read_csv(test_path + 'test_detests_df_a1_preprocesado.csv', encoding = 'UTF-8', sep=',')\n",
        "valid_df = pd.read_csv(data_path + 'valid_detests_df_a1_bt.csv', encoding = 'UTF-8', sep=',')\n",
        "\n",
        "nombre_etiqueta = 'label'\n",
        "campo_texto = 'text'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ABH1WHyvFOU",
        "outputId": "8cc2f6ea-5145-48a9-af6a-5c28b676459a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribución original - Train:  label\n",
            "0    2779\n",
            "1    2112\n",
            "dtype: int64\n",
            "Distribución original - Valid:  label\n",
            "0    797\n",
            "1    601\n",
            "dtype: int64\n",
            "Distribución original - Test:  label\n",
            "0    402\n",
            "1    161\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Para saber el número de filas de cada clase en cada división\n",
        "print(\"Distribución original - Train: \", train_df.value_counts(nombre_etiqueta))\n",
        "print(\"Distribución original - Valid: \", valid_df.value_counts(nombre_etiqueta))\n",
        "print(\"Distribución original - Test: \", test_df.value_counts(nombre_etiqueta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw3QmtuRaNxv"
      },
      "source": [
        "## Reducción de los ficheros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiJlJSRmaNxv"
      },
      "outputs": [],
      "source": [
        "porcentaje = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX1qgst0aNxv",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "t1, t2 = train_test_split(train_df, test_size = porcentaje, stratify = train_df[nombre_etiqueta])\n",
        "v1, v2 = train_test_split(valid_df, test_size = porcentaje, stratify = valid_df[nombre_etiqueta])\n",
        "\n",
        "train_df_reduced = t1\n",
        "valid_df_reduced = v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZZJT3GYaNxv"
      },
      "outputs": [],
      "source": [
        "red_path = '/home/manuelcerrejon/TFG/Task 1/Detests/Hiperparametros/Datos/'\n",
        "\n",
        "train_df_reduced.to_csv(red_path + \"train_df_reducido_a1.csv\", index=False)\n",
        "valid_df_reduced.to_csv(red_path + \"valid_df_reducido_a1.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT2X7S4saNxw"
      },
      "source": [
        "## Lectura de ficheros reducidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8oVAJD3aNxw"
      },
      "outputs": [],
      "source": [
        "# data_path = './'\n",
        "data_path = '/home/manuelcerrejon/TFG/Task 1/Detests/Hiperparametros/Datos/'\n",
        "test_path = '/home/manuelcerrejon/TFG/Task 1/Detests/Preprocesing/Datos/'\n",
        "\n",
        "train_df = pd.read_csv(data_path + 'train_df_reducido_a1.csv', encoding = 'UTF-8', sep=',')\n",
        "test_df = pd.read_csv(test_path + 'test_detests_df_a1_preprocesado.csv', encoding = 'UTF-8', sep=',')\n",
        "valid_df = pd.read_csv(data_path + 'valid_df_reducido_a1.csv', encoding = 'UTF-8', sep=',')\n",
        "\n",
        "nombre_etiqueta = 'label'\n",
        "campo_texto = 'text'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfySuxu9aNxx",
        "outputId": "d354ac2b-84d1-49a3-88eb-6113522c80d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribución original - Train:  label\n",
            "0    2223\n",
            "1    1689\n",
            "dtype: int64\n",
            "Distribución original - Valid:  label\n",
            "0    637\n",
            "1    481\n",
            "dtype: int64\n",
            "Distribución original - Test:  label\n",
            "0    402\n",
            "1    161\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Para saber el número de filas de cada clase en cada división\n",
        "print(\"Distribución original - Train: \", train_df.value_counts(nombre_etiqueta))\n",
        "print(\"Distribución original - Valid: \", valid_df.value_counts(nombre_etiqueta))\n",
        "print(\"Distribución original - Test: \", test_df.value_counts(nombre_etiqueta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAwEozrCwqYo"
      },
      "source": [
        "## Limpieza de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "_AxumHJUwwao",
        "outputId": "5b47b0f3-76a9-48fa-81f4-7d86686e8056"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_split</th>\n",
              "      <th>num_palabras</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d_118_02</td>\n",
              "      <td>pero si, como dices vamos para atrás, el otro ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[pero, si,, como, dices, vamos, para, atrás,, ...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d_909_01</td>\n",
              "      <td>en realidad no, es inmune, da igual el delito,...</td>\n",
              "      <td>0</td>\n",
              "      <td>[en, realidad, no,, es, inmune,, da, igual, el...</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d_1116_02</td>\n",
              "      <td>en fin hay gente muy valiente.</td>\n",
              "      <td>0</td>\n",
              "      <td>[en, fin, hay, gente, muy, valiente.]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d_142_02</td>\n",
              "      <td>Solo ha que ver videos de barbaridades de lo q...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Solo, ha, que, ver, videos, de, barbaridades,...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d_824_01</td>\n",
              "      <td>Es lógico, son 600.000 votos sobre la base de ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Es, lógico,, son, 600.000, votos, sobre, la, ...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>d_1831_03</td>\n",
              "      <td>de estos temas no está ni se le espera</td>\n",
              "      <td>0</td>\n",
              "      <td>[de, estos, temas, no, está, ni, se, le, espera]</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>d_1002_01</td>\n",
              "      <td>A ver yo no soy racista no , pero me gusta el ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[A, ver, yo, no, soy, racista, no, ,, pero, me...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>d_752_03</td>\n",
              "      <td>De esta manera aportarán dinero al Estado y a ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[De, esta, manera, aportarán, dinero, al, Esta...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>d_321_01</td>\n",
              "      <td>se le ve equilibrado, eso por un zumo en alta ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[se, le, ve, equilibrado,, eso, por, un, zumo,...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>d_653_04</td>\n",
              "      <td>Creo que lo primero es dar trabajo a los españ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Creo, que, lo, primero, es, dar, trabajo, a, ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3912 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                                               text  label  \\\n",
              "0      d_118_02  pero si, como dices vamos para atrás, el otro ...      0   \n",
              "1      d_909_01  en realidad no, es inmune, da igual el delito,...      0   \n",
              "2     d_1116_02                     en fin hay gente muy valiente.      0   \n",
              "3      d_142_02  Solo ha que ver videos de barbaridades de lo q...      1   \n",
              "4      d_824_01  Es lógico, son 600.000 votos sobre la base de ...      1   \n",
              "...         ...                                                ...    ...   \n",
              "3907  d_1831_03             de estos temas no está ni se le espera      0   \n",
              "3908  d_1002_01  A ver yo no soy racista no , pero me gusta el ...      1   \n",
              "3909   d_752_03  De esta manera aportarán dinero al Estado y a ...      1   \n",
              "3910   d_321_01  se le ve equilibrado, eso por un zumo en alta ...      0   \n",
              "3911   d_653_04  Creo que lo primero es dar trabajo a los españ...      1   \n",
              "\n",
              "                                             text_split  num_palabras  \n",
              "0     [pero, si,, como, dices, vamos, para, atrás,, ...            27  \n",
              "1     [en, realidad, no,, es, inmune,, da, igual, el...            38  \n",
              "2                 [en, fin, hay, gente, muy, valiente.]             6  \n",
              "3     [Solo, ha, que, ver, videos, de, barbaridades,...            29  \n",
              "4     [Es, lógico,, son, 600.000, votos, sobre, la, ...            19  \n",
              "...                                                 ...           ...  \n",
              "3907   [de, estos, temas, no, está, ni, se, le, espera]             9  \n",
              "3908  [A, ver, yo, no, soy, racista, no, ,, pero, me...            20  \n",
              "3909  [De, esta, manera, aportarán, dinero, al, Esta...            20  \n",
              "3910  [se, le, ve, equilibrado,, eso, por, un, zumo,...            23  \n",
              "3911  [Creo, que, lo, primero, es, dar, trabajo, a, ...            10  \n",
              "\n",
              "[3912 rows x 5 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Esto solo es para ver la longitud (en palabras) de los tweets\n",
        "def divide(texto):\n",
        "  return texto.split()\n",
        "\n",
        "def cuenta_tokens(lista):\n",
        "  return len(lista)\n",
        "\n",
        "train_df_palabras = train_df.copy()\n",
        "train_df_palabras['text_split'] = train_df_palabras[campo_texto].apply(divide)\n",
        "train_df_palabras['num_palabras'] = train_df_palabras['text_split'].apply(cuenta_tokens)\n",
        "train_df_palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlzGRIVnxK3f",
        "outputId": "3d718687-c6a6-4a46-da5e-0fbd5abbb6e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El texto de mayor longitud tiene 181 palabras\n"
          ]
        }
      ],
      "source": [
        "max = train_df_palabras.max()['num_palabras']\n",
        "print(f'El texto de mayor longitud tiene {max} palabras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuvdBvkpU2-l",
        "outputId": "84b7c8a5-7cca-47aa-ba47-527c10647f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'text', 'label'],\n",
            "    num_rows: 3912\n",
            "}) Dataset({\n",
            "    features: ['id', 'text', 'label'],\n",
            "    num_rows: 1118\n",
            "}) Dataset({\n",
            "    features: ['id', 'text', 'label'],\n",
            "    num_rows: 563\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Se convierten los dataframes en objetos datasets para que los acepten los transformers\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "valid_dataset = Dataset.from_pandas(valid_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "print(train_dataset, valid_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "I4HDHXTPVeQZ",
        "outputId": "0ff4caa2-a96b-408b-b694-17818226d701"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d_118_02</td>\n",
              "      <td>pero si, como dices vamos para atrás, el otro ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d_909_01</td>\n",
              "      <td>en realidad no, es inmune, da igual el delito,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d_1116_02</td>\n",
              "      <td>en fin hay gente muy valiente.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d_142_02</td>\n",
              "      <td>Solo ha que ver videos de barbaridades de lo q...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d_824_01</td>\n",
              "      <td>Es lógico, son 600.000 votos sobre la base de ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>d_1831_03</td>\n",
              "      <td>de estos temas no está ni se le espera</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>d_1002_01</td>\n",
              "      <td>A ver yo no soy racista no , pero me gusta el ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>d_752_03</td>\n",
              "      <td>De esta manera aportarán dinero al Estado y a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>d_321_01</td>\n",
              "      <td>se le ve equilibrado, eso por un zumo en alta ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>d_653_04</td>\n",
              "      <td>Creo que lo primero es dar trabajo a los españ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3912 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                                               text  label\n",
              "0      d_118_02  pero si, como dices vamos para atrás, el otro ...      0\n",
              "1      d_909_01  en realidad no, es inmune, da igual el delito,...      0\n",
              "2     d_1116_02                     en fin hay gente muy valiente.      0\n",
              "3      d_142_02  Solo ha que ver videos de barbaridades de lo q...      1\n",
              "4      d_824_01  Es lógico, son 600.000 votos sobre la base de ...      1\n",
              "...         ...                                                ...    ...\n",
              "3907  d_1831_03             de estos temas no está ni se le espera      0\n",
              "3908  d_1002_01  A ver yo no soy racista no , pero me gusta el ...      1\n",
              "3909   d_752_03  De esta manera aportarán dinero al Estado y a ...      1\n",
              "3910   d_321_01  se le ve equilibrado, eso por un zumo en alta ...      0\n",
              "3911   d_653_04  Creo que lo primero es dar trabajo a los españ...      1\n",
              "\n",
              "[3912 rows x 3 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Los objetos de tipo Dataset también se pueden mostrar en formato pandas\n",
        "train_dataset.set_format(\"pandas\")\n",
        "train_dataset[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBXGEi22VmuC"
      },
      "outputs": [],
      "source": [
        "# Se pueden eliminar los dataframes puesto que no se van a usar más\n",
        "del train_df\n",
        "del valid_df\n",
        "del test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP-SpeeiXaNr"
      },
      "source": [
        "# Preparación de los conjuntos para el entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUj7y7eTXiZ6"
      },
      "outputs": [],
      "source": [
        "# Se asigna una etiqueta numérica en función de la etiqueta principal\n",
        "\n",
        "def set_labels(records):\n",
        "  if records[nombre_etiqueta] == 0:\n",
        "    label = 0\n",
        "  else:\n",
        "    label = 1\n",
        "  return {'labels': label}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xKfyjO-l36a"
      },
      "outputs": [],
      "source": [
        "# Reseteamos el formato para que no haya fallos\n",
        "train_dataset.reset_format()\n",
        "valid_dataset.reset_format()\n",
        "test_dataset.reset_format()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207,
          "referenced_widgets": [
            "54eb4a782930414b8a6f442eeb78e3f2",
            "3b61e5b213e24e7092261020348191c7",
            "a288ab582c5f4c6aa2584045fd19ff38",
            "9f03a3c4ddfc4db1b9ecee92b7284865",
            "edb4e7063ee142a1bd1d46a78706a546",
            "77f24e86a5fc451faa2d5d4a66c99848",
            "5486aaaf85e542aebc4a86f969bfc1e8",
            "8b86e2db3c3d4d9b8199cfbfb34ccc3f",
            "fee59c728d434b08bb164d41e8e12c17",
            "6730f6beb6e1481b86687377b48378b2",
            "6623277ff0944c96b0288617a864c7a4",
            "d945728de0fc4f4686adf8ae3920d165",
            "0bf45adaaa6242528683a5b7495dd768",
            "935ce0134f2a430da156cfc14d082dbc",
            "56d90fad3faa4fb38ec2da42c9b7416f",
            "a396650be2ad40efa13a83e5fd9973e4",
            "55b33092c0cf4a77a732e475a7f219ac",
            "e6a588ceb89342789114abb2602437a4",
            "ecf569392ed34d4aaaa58268deba246a",
            "ad618b76b63d47f290dd8cf7660ac789",
            "4e1e87dbf8954b878de9bd2c8361e17d",
            "9fd55ce7d3714e18ba68a01cdda09a55",
            "274a6c32732547a3a7702d153ef2c4bb",
            "4d66cb1bc8a5484c8962f3fa9b44cf6a"
          ]
        },
        "id": "E3BnmeavYAjy",
        "outputId": "8d6c403d-6f89-4e46-d4f5-691e532246f3",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "274a6c32732547a3a7702d153ef2c4bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3912 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d66cb1bc8a5484c8962f3fa9b44cf6a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1118 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'text', 'label', 'labels'],\n",
            "    num_rows: 3912\n",
            "}) Dataset({\n",
            "    features: ['id', 'text', 'label', 'labels'],\n",
            "    num_rows: 1118\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Map the functions to the dataset\n",
        "train_dataset = train_dataset.map(set_labels)\n",
        "valid_dataset = valid_dataset.map(set_labels)\n",
        "\n",
        "print(train_dataset, valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeigQvySYgVG"
      },
      "outputs": [],
      "source": [
        "# Reseteamos el formato para que no haya fallos\n",
        "train_dataset.reset_format()\n",
        "valid_dataset.reset_format()\n",
        "test_dataset.reset_format()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHW8R_56TzDx"
      },
      "source": [
        "# Proceso de clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SoLh_uYZcAl"
      },
      "source": [
        "## Tokenización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVqKANYiaNx1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "4df159e4f1c54c66952b760835ce00cc",
            "698d1823144043bda14c2e074b55ad03",
            "13733d4050b64837abb9295ccfab309d",
            "d2863650485a4a5ebde49209d531dd75",
            "d7eb939ee90c4b02abd85280325bdf89",
            "6a01d3f6fb2d4eebaeefe9a293872819",
            "196d29670dad494f9ba8eccfea136748",
            "54f0503fe5a141168f9a5a7a56f9433c",
            "3998113b42904ac886361cdc104525a0",
            "fbd87348304045d19ff3282b99e9c5df",
            "edd76269e67d47bf9fd38ab9afd25e16",
            "e05caf83094841e3b1446c378b7c40d2",
            "043fe75af7434bcaa9915ce3ebe16c89",
            "7c1177cf551b41cfb84276eb4333f8b4",
            "8f82adf939984ef49d272fa3cb8963d0",
            "4e01afcdd48d4515861d53a1a14e0a35",
            "c0e613eb3a5d4aa8b76ee4a6ecc46dfb",
            "d9d288706f524fe2888c14a6de03d662",
            "c08dce0752ec463b82d7a0f9a56339bb",
            "d951209835ab40e69350b73c9e52caa2",
            "b0f23834611b4f0e90e205a7d82fdf71",
            "86707ad3a58f4d3d98905940821f2b60",
            "82b1e9dc42014b788216babedfc32228",
            "13822134801245f1a9645315fec1d392",
            "0ab62d2085714b80b1f591bf4ff267fe",
            "9f74313014de4c9782ec9ea67e616741",
            "b00afd73a5fc4682956ce6533f41e2b0",
            "4bd5c9dd61c44eb68863cecb0dd97162",
            "e9757fe3c528491885f9c87ba3a5d274",
            "ef432f0fa60842f0bdf57133456db3bb",
            "982a2861a18447cdbdd367652c6a87b5",
            "23bc8e346ac34979916adf1878052a27",
            "12db505168ee4d10a763a4b2d6ba6853",
            "9971ec27c00440ed8232876fbc7735b9",
            "56bc73153e1141ed90994f5ad6e2f33e",
            "9a6df6fe531747848ce88e9d322ee9a5",
            "91e522f4a31d4cb8ac5c0d14b3233da6",
            "6ce8131571d246348c0863cc270a6a22"
          ]
        },
        "id": "UrHQenA5IGS7",
        "outputId": "8f8e69c9-fae2-44c8-d768-1f7d140a1d23"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9971ec27c00440ed8232876fbc7735b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56bc73153e1141ed90994f5ad6e2f33e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/851k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a6df6fe531747848ce88e9d322ee9a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/509k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91e522f4a31d4cb8ac5c0d14b3233da6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.21M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ce8131571d246348c0863cc270a6a22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Wz6PKiaWYr",
        "outputId": "70bacd3a-bde8-4982-c6e2-a6d549c3e95d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50262"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tamaño del vocabulario del tokenizador\n",
        "tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk_zEHiCaNx2",
        "outputId": "0c71dbae-77e7-45ba-9a2f-5b50a9ec5645",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3912/3912 [00:00<00:00, 11725.66it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1118/1118 [00:00<00:00, 12270.30it/s]\n"
          ]
        }
      ],
      "source": [
        "# Crear un contenedor para los conteos de tokens por tweet\n",
        "conteos_token_train = []\n",
        "conteos_token_valid = []\n",
        "# Tokenizar todos los tweets y registrar el número de tokens\n",
        "for tweet in tqdm(train_dataset):\n",
        "    tokens = tokenizer.tokenize(tweet[campo_texto])\n",
        "    conteos_token_train.append(len(tokens))\n",
        "for tweet in tqdm(valid_dataset):\n",
        "    tokens = tokenizer.tokenize(tweet[campo_texto])\n",
        "    conteos_token_valid.append(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "qEZlUQJQaNx2",
        "outputId": "ff6103ef-35e2-4c99-c199-d6ee3465de72",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "del max\n",
        "\n",
        "# Crear subgráficos\n",
        "fig, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (18, 6))\n",
        "fig.suptitle('Histograma del Número de Tokens por Tweet', fontsize = 16)\n",
        "\n",
        "# Subgráfico para el conjunto train\n",
        "max_tokens_train = max(conteos_token_train)\n",
        "axes[0].hist(conteos_token_train, color='blanchedalmond')\n",
        "axes[0].set_title('Train Set')\n",
        "axes[0].set_xlabel('Número de Tokens')\n",
        "axes[0].set_ylabel('Frecuencia')\n",
        "axes[0].legend(['Max Tokens:' + str(max_tokens_train)])\n",
        "\n",
        "# Subgráfico para el conjunto valid\n",
        "max_tokens_valid = max(conteos_token_valid)\n",
        "axes[1].hist(conteos_token_valid, color='lightpink')\n",
        "axes[1].set_title('Valid Set')\n",
        "axes[1].set_xlabel('Número de Tokens')\n",
        "axes[1].set_ylabel('Frecuencia')\n",
        "axes[1].legend(['Max Tokens:' + str(max_tokens_valid)])\n",
        "\n",
        "# Ajustar el diseño y mostrar los subgráficos\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSke1WGFaNx2"
      },
      "source": [
        "#### *Definir Longitud Máxima*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgWfF8EHaNx2"
      },
      "outputs": [],
      "source": [
        "# Definir MAX_LENGTH\n",
        "MAX_LENGTH = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UTSkRAva2xI"
      },
      "outputs": [],
      "source": [
        "# Función para tokenizar un dataset\n",
        "def tokenize_data(examples):\n",
        "  #return tokenizer(examples[campo_texto], truncation=True, padding='longest')\n",
        "  return tokenizer(examples[campo_texto], truncation=True, max_length=MAX_LENGTH, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "10d5513b455146feac21f8e8d2d75370",
            "5719c4165b564b81b75ac192a7abcd68",
            "9a1b5d1572064740a8930f73a6063ec5",
            "9a5847022353488c830020f36264bd68",
            "8bf1f8d41ede4c96afbe812115f8ba10",
            "8ba0dc34b57741a997758359dbbc1abd",
            "fac91a645811443a909ed0bc1e4a2c7b",
            "de4cae2e052f47c591ccaa21478fbf4c",
            "06accd97ad254d5a9afc43309ba91ab1",
            "08221f205e7c476ea486051cb39d13fa",
            "8577cd3673f44958b12b541c55769ec1",
            "089aaf939e4b40ff88be45755dd64845",
            "f2f9d6c6e74340078ff89adfafd72135",
            "1681060bf11d474c874db850fcd5d197",
            "1f6b5b8c4db640bda1febf0a83afcfcf",
            "0a0e53e5a6664c19803573c891f80ca5",
            "e0c10252e3ad4a22bd47f62eff62e406",
            "e6a148f5d7534b9bb0a82f771f21b042",
            "d3b4a2e7d0d84bddabc11a198ee49784",
            "526fc67bef94444ca6901ea0e002f12c",
            "89400a1a138b4ac584853e9a5f959d04",
            "c0730f106b8a416db58b9ea5b89cbfbb",
            "cf9d9e4692cd4bdfa266493c3ca799dd",
            "d71bf71d7d8344e8917db80f818dcd35"
          ]
        },
        "id": "8ez_j2tga8dh",
        "outputId": "8115561e-9763-4941-d564-4a2e3fd61d36"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf9d9e4692cd4bdfa266493c3ca799dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3912 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d71bf71d7d8344e8917db80f818dcd35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1118 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['labels', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 3912\n",
              "})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Celda para para construir los ficheros codificados (encoded)\n",
        "columns_train = train_dataset.column_names  # Coge todas las columnas\n",
        "columns_valid = valid_dataset.column_names  # Coge todas las columnas\n",
        "columns_train.remove(\"labels\") # Elimina la columna \"labels\"\n",
        "columns_valid.remove(\"labels\") # Elimina la columna \"labels\"\n",
        "\n",
        "# Hace el tokenizado y elimina todas las columnas que no se necesitan\n",
        "encoded_train_dataset = train_dataset.map(tokenize_data, batched=True, remove_columns=columns_train)\n",
        "encoded_valid_dataset = valid_dataset.map(tokenize_data, batched=True, remove_columns=columns_valid)\n",
        "encoded_train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGkSIC5IcU1W"
      },
      "outputs": [],
      "source": [
        "len(encoded_train_dataset[3]['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r0gjSybcbgq",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "encoded_train_dataset[4]['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVBW0d7L3UfH",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "encoded_train_dataset[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXciKuEfdNq0"
      },
      "source": [
        "## Carga del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztAg7H_pdT4J"
      },
      "outputs": [],
      "source": [
        "# Se carga el modelo preentrenado\n",
        "n_labels = 2\n",
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint,\n",
        "                                                              num_labels = n_labels)\n",
        "                                                              # use_auth_token = 'token propio de HugginFace')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "oZYGeGF6aNx8",
        "outputId": "acb21c4e-325c-4734-e970-bc99e518bd12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'roberta-base-bne'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Para saber el nombre del modelo\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "model_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E54xHqcSektF"
      },
      "source": [
        "## Definición de la métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLVGRzgoepR-"
      },
      "outputs": [],
      "source": [
        "# Función para realizar distintas métricas en ejecución\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "  ##############\n",
        "  ## preds son logits, que son tuplas de la forma [valor1, valor2]\n",
        "  ## Por ejemplo [-1.5606991,  1.6122842] significa que ha predicho eso para un documento\n",
        "  ## Eso es lo que pasa a la última capa del transformer (softmax si es binario)\n",
        "  ## Por eso se utiliza el índice del valor máximo de la tupla, para decir que esa es la clase que predice\n",
        "  ##############\n",
        "\n",
        "  labels = eval_pred.label_ids\n",
        "  preds = eval_pred.predictions.argmax(-1)\n",
        "\n",
        "  precision, recall, f1, _ = sk.metrics.precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
        "  f1_minoritaria = f1_score(labels, preds, pos_label=1)\n",
        "  f1_mayoritaria = f1_score(labels, preds, pos_label=0)\n",
        "  acc = sk.metrics.accuracy_score(labels, preds)\n",
        "  AUC = roc_auc_score(labels, preds)\n",
        "  PREC_REC = average_precision_score(labels, preds)\n",
        "  return { 'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall, 'AUC': AUC,\n",
        "           'f1_minoritaria': f1_minoritaria, 'f1_mayoritaria': f1_mayoritaria, 'PREC_REC': PREC_REC }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elw5JWOAe2vz",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "##### Otra forma de definir las métricas\n",
        "'''\n",
        "accuracy = load_metric('accuracy')\n",
        "f1 = load_metric('f1')\n",
        "\n",
        "def compute_metric(eval_pred, test=False):\n",
        "  predictions, labels = eval_pred\n",
        "\n",
        "  if test == False:\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "  result_acc = accuracy.compute(predictions=predictions, references=labels)['accuracy']\n",
        "  result_f1 = f1.compute(predictions=predictions, references=labels)['f1']\n",
        "\n",
        "  return {'accuracy': result_acc, 'f1-score': result_f1}\n",
        "  '''\n",
        "##### Otra forma de definir las métricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jWjscxYaNx9"
      },
      "source": [
        "## Configuración de la búsqueda de hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a18r-PLTaNx-"
      },
      "source": [
        "#### *Definir el Número de Épocas*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzkv0mcsaNx-"
      },
      "outputs": [],
      "source": [
        "# Definir NUM_TRAIN_EPOCHS\n",
        "NUM_TRAIN_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxZ9bKFJaNx-"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VabGrYDbaNx-"
      },
      "outputs": [],
      "source": [
        "def maximum(a, b):\n",
        "    if a >= b:\n",
        "        return a\n",
        "    else:\n",
        "        return b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLfj7CXjaNx_"
      },
      "source": [
        "#### *Estructura de Búsqueda*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQrol_K7aNx_"
      },
      "outputs": [],
      "source": [
        "# Crear un espacio de búsqueda de hiperparámetros\n",
        "search_space = {\n",
        "    \"per_device_train_batch_size\": [16, 32],\n",
        "    \"learning_rate\": [3e-5, 5e-5],\n",
        "    \"weight_decay\": [0.01, 0.1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCu-wp-paNx_"
      },
      "outputs": [],
      "source": [
        "# Calcular Numero de busquedas\n",
        "nbusquedas = 1\n",
        "for options in search_space.values():\n",
        "    nbusquedas *= len(options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92UaglwlaNx_"
      },
      "outputs": [],
      "source": [
        "# Función objetivo para Optuna\n",
        "def compute_objective(trial):\n",
        "\n",
        "    # Obtener los hiperparámetros sugeridos por Optuna\n",
        "    # hparams = optuna_hp_space(trial)\n",
        "    hparams = {key: trial.suggest_categorical(key, values) for key, values in search_space.items()}\n",
        "\n",
        "    # Se definen los parámetros del Trainer()\n",
        "    num_train_samples = int(len(encoded_train_dataset))\n",
        "    num_evaluation= int(len(encoded_valid_dataset))\n",
        "\n",
        "    value = len(encoded_train_dataset) // (2 * hparams[\"per_device_train_batch_size\"] * NUM_TRAIN_EPOCHS)\n",
        "    logging_steps = maximum(1, value)\n",
        "\n",
        "    optim = [\"adamw_hf\", \"adamw_torch\", \"adamw_apex_fused\", \"adafactor\", \"adamw_torch_xla\"]\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='results',\n",
        "        num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "        learning_rate=hparams[\"learning_rate\"],\n",
        "        per_device_train_batch_size=hparams[\"per_device_train_batch_size\"],\n",
        "        per_device_eval_batch_size=hparams[\"per_device_train_batch_size\"],\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='f1',\n",
        "        weight_decay=hparams[\"weight_decay\"],\n",
        "        evaluation_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        save_total_limit=3,\n",
        "        optim=optim[1],\n",
        "        push_to_hub=False\n",
        "    )\n",
        "\n",
        "    # Configurar el objeto Trainer con los hiperparámetros dados\n",
        "    trainer = Trainer(\n",
        "        model_init=model_init,\n",
        "        args=training_args,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "        train_dataset=encoded_train_dataset,\n",
        "        eval_dataset=encoded_valid_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    # Entrenar el modelo y obtener la métrica de interés\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluar el modelo en el conjunto de validación\n",
        "    result = trainer.evaluate()\n",
        "    print(result)\n",
        "\n",
        "    # Obtener la métrica de interés, en este caso, F1\n",
        "    metric = result['eval_f1']\n",
        "\n",
        "    # Devolver la métrica como resultado para la optimización de Optuna\n",
        "    return metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5Wc1_jjaNyA"
      },
      "outputs": [],
      "source": [
        "best_number = 0\n",
        "best_result = 0\n",
        "\n",
        "# ruta_callback = './hp/'\n",
        "ruta_callback = '/home/manuelcerrejon/TFG/Task 1/Detests/Hiperparametros/Resultados/'\n",
        "\n",
        "# Callback para guardar los resultados en cada iteración\n",
        "def callback(study, trial, busqueda, modelo):\n",
        "    # Obtener la información relevante de la iteración actual\n",
        "    trial_value = trial.value\n",
        "    trial_params = trial.params\n",
        "\n",
        "    global best_result, best_number\n",
        "\n",
        "    # Actualizar el mejor resultado\n",
        "    if trial_value > best_result:\n",
        "        best_number = trial.number\n",
        "        best_result = trial_value\n",
        "\n",
        "    # Guardar los resultados en un archivo o en cualquier otra estructura de datos\n",
        "    with open(ruta_callback + 'hiperparametros_' + busqueda +'_' + modelo +'.txt', 'a') as f:\n",
        "        if trial.number == 0:\n",
        "            f.write(f\"Estudio de Hiperparámetros. Búsqueda: {busqueda}, Modelo: {modelo}\\n\\n\")\n",
        "        f.write(f\"Iteración: {trial.number}, Valor: {trial_value}, HP: {trial_params}, Mejor: {best_number}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP8GF7ZRaNyA"
      },
      "source": [
        "## Estudio de hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_MSsM7RaNyA"
      },
      "outputs": [],
      "source": [
        "# # Búsqueda heurística\n",
        "# metodo = 'heuristica'\n",
        "# study = optuna.create_study(direction='maximize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCtusLROaNyB"
      },
      "outputs": [],
      "source": [
        "# # Búsqueda aleatoria\n",
        "# metodo = 'aleatoria'\n",
        "# study = optuna.create_study(sampler=optuna.samplers.RandomSampler(), direction='maximize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKhtvRsUaNyB",
        "outputId": "88d9d1be-aea2-4f4c-bff8-d73cd1743381"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 10:57:43,345] A new study created in memory with name: no-name-436749fb-3adb-45b8-b742-1ad7500e21a1\n"
          ]
        }
      ],
      "source": [
        "# Búsqueda exhaustiva\n",
        "metodo = 'exhaustiva'\n",
        "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.GridSampler(search_space))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "q_AcVxrQaNyB",
        "outputId": "2e8106c4-4c0c-494e-8e13-b9b09876ba45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'roberta'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtener nombre del modelo acortado\n",
        "model_short = model_name.split(\"-\")[0]\n",
        "# model_short = 'prueba'\n",
        "model_short"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DApEFPpdaNyB"
      },
      "outputs": [],
      "source": [
        "# Crear una versión de callback con argumentos fijos\n",
        "partial_callback = partial(callback, busqueda=metodo, modelo=model_short)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986,
          "referenced_widgets": [
            "1b5bb11f9c0545479b54404e5eaef5dd",
            "d87c1cce342a49f4ac21c06421eb2110",
            "fa838dfed7da4300aab490d6b9cf9659",
            "de8e865d38284203863248a8423f684e",
            "1fad39e5458b499c967160adab1e4842",
            "10556e66bc38414396eb2f08825dfb97",
            "2d4ad5c899054421ac6f3f8dfcf1ed04",
            "ef05e5efb76941cf9bf43cc0c8f7d1c0",
            "784536dd26c649c3b42c1bb09277b326",
            "e23d985cf2dc446b9d5391b000988538",
            "fe2bbb5b0f6d45e481bb753126b35559",
            "fb1fa210b9f84959a63439d331e4fee7",
            "92eb43717869437a88a0a6f752a842d0"
          ]
        },
        "id": "b1Eo03qBaNyB",
        "outputId": "287c25dd-13a0-46a6-8471-95e7209e2590",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb1fa210b9f84959a63439d331e4fee7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92eb43717869437a88a0a6f752a842d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 3912\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1230\n",
            "  Number of trainable parameters = 124644866\n",
            "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='615' max='1230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 615/1230 02:07 < 02:07, 4.82 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Auc</th>\n",
              "      <th>F1 Minoritaria</th>\n",
              "      <th>F1 Mayoritaria</th>\n",
              "      <th>Prec Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.348976</td>\n",
              "      <td>0.862254</td>\n",
              "      <td>0.854881</td>\n",
              "      <td>0.877072</td>\n",
              "      <td>0.847299</td>\n",
              "      <td>0.847299</td>\n",
              "      <td>0.822171</td>\n",
              "      <td>0.887591</td>\n",
              "      <td>0.796182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.337424</td>\n",
              "      <td>0.866726</td>\n",
              "      <td>0.862720</td>\n",
              "      <td>0.867646</td>\n",
              "      <td>0.859625</td>\n",
              "      <td>0.859625</td>\n",
              "      <td>0.839266</td>\n",
              "      <td>0.886173</td>\n",
              "      <td>0.787664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.596160</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.845616</td>\n",
              "      <td>0.847812</td>\n",
              "      <td>0.854555</td>\n",
              "      <td>0.854555</td>\n",
              "      <td>0.836502</td>\n",
              "      <td>0.854730</td>\n",
              "      <td>0.741567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.753563</td>\n",
              "      <td>0.854204</td>\n",
              "      <td>0.847222</td>\n",
              "      <td>0.864332</td>\n",
              "      <td>0.840744</td>\n",
              "      <td>0.840744</td>\n",
              "      <td>0.814562</td>\n",
              "      <td>0.879882</td>\n",
              "      <td>0.779498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.161500</td>\n",
              "      <td>0.790926</td>\n",
              "      <td>0.863148</td>\n",
              "      <td>0.859948</td>\n",
              "      <td>0.861368</td>\n",
              "      <td>0.858776</td>\n",
              "      <td>0.858776</td>\n",
              "      <td>0.838778</td>\n",
              "      <td>0.881119</td>\n",
              "      <td>0.777920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-123\n",
            "Configuration saved in results/checkpoint-123/config.json\n",
            "Model weights saved in results/checkpoint-123/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-123/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-123/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-246\n",
            "Configuration saved in results/checkpoint-246/config.json\n",
            "Model weights saved in results/checkpoint-246/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-246/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-246/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-369] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-369\n",
            "Configuration saved in results/checkpoint-369/config.json\n",
            "Model weights saved in results/checkpoint-369/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-369/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-369/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-492] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-492\n",
            "Configuration saved in results/checkpoint-492/config.json\n",
            "Model weights saved in results/checkpoint-492/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-492/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-492/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-123] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-615\n",
            "Configuration saved in results/checkpoint-615/config.json\n",
            "Model weights saved in results/checkpoint-615/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-615/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-615/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-369] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-246 (score: 0.8627195508977348).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 11:00:13,539] Trial 0 finished with value: 0.8627195508977348 and parameters: {'per_device_train_batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.01}. Best is trial 0 with value: 0.8627195508977348.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.33742401003837585, 'eval_accuracy': 0.8667262969588551, 'eval_f1': 0.8627195508977348, 'eval_precision': 0.8676462737561392, 'eval_recall': 0.8596249310535025, 'eval_AUC': 0.8596249310535025, 'eval_f1_minoritaria': 0.8392664509169363, 'eval_f1_mayoritaria': 0.8861726508785333, 'eval_PREC_REC': 0.7876635108358958, 'eval_runtime': 1.9916, 'eval_samples_per_second': 561.344, 'eval_steps_per_second': 17.573, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 3912\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2450\n",
            "  Number of trainable parameters = 124644866\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='980' max='2450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 980/2450 01:57 < 02:57, 8.30 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Auc</th>\n",
              "      <th>F1 Minoritaria</th>\n",
              "      <th>F1 Mayoritaria</th>\n",
              "      <th>Prec Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.352445</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.845195</td>\n",
              "      <td>0.845016</td>\n",
              "      <td>0.851754</td>\n",
              "      <td>0.851754</td>\n",
              "      <td>0.833010</td>\n",
              "      <td>0.857380</td>\n",
              "      <td>0.743454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.463089</td>\n",
              "      <td>0.848837</td>\n",
              "      <td>0.840542</td>\n",
              "      <td>0.863156</td>\n",
              "      <td>0.833234</td>\n",
              "      <td>0.833234</td>\n",
              "      <td>0.804171</td>\n",
              "      <td>0.876912</td>\n",
              "      <td>0.775172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.302600</td>\n",
              "      <td>0.700222</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.835676</td>\n",
              "      <td>0.834428</td>\n",
              "      <td>0.840087</td>\n",
              "      <td>0.840087</td>\n",
              "      <td>0.819802</td>\n",
              "      <td>0.851550</td>\n",
              "      <td>0.733525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.302600</td>\n",
              "      <td>0.828857</td>\n",
              "      <td>0.842576</td>\n",
              "      <td>0.838850</td>\n",
              "      <td>0.840312</td>\n",
              "      <td>0.837668</td>\n",
              "      <td>0.837668</td>\n",
              "      <td>0.814346</td>\n",
              "      <td>0.863354</td>\n",
              "      <td>0.748277</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-245\n",
            "Configuration saved in results/checkpoint-245/config.json\n",
            "Model weights saved in results/checkpoint-245/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-245/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-245/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-246] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-490\n",
            "Configuration saved in results/checkpoint-490/config.json\n",
            "Model weights saved in results/checkpoint-490/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-490/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-490/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-492] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-735\n",
            "Configuration saved in results/checkpoint-735/config.json\n",
            "Model weights saved in results/checkpoint-735/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-735/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-735/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-615] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-980\n",
            "Configuration saved in results/checkpoint-980/config.json\n",
            "Model weights saved in results/checkpoint-980/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-980/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-980/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-490] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-245 (score: 0.8451947382826965).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 11:02:14,946] Trial 1 finished with value: 0.8451947382826965 and parameters: {'per_device_train_batch_size': 16, 'learning_rate': 5e-05, 'weight_decay': 0.1}. Best is trial 0 with value: 0.8627195508977348.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3524446189403534, 'eval_accuracy': 0.8461538461538461, 'eval_f1': 0.8451947382826965, 'eval_precision': 0.8450161821621673, 'eval_recall': 0.8517544231829945, 'eval_AUC': 0.8517544231829947, 'eval_f1_minoritaria': 0.8330097087378641, 'eval_f1_mayoritaria': 0.8573797678275291, 'eval_PREC_REC': 0.7434544723908048, 'eval_runtime': 1.9745, 'eval_samples_per_second': 566.21, 'eval_steps_per_second': 35.451, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 3912\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2450\n",
            "  Number of trainable parameters = 124644866\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2205' max='2450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2205/2450 04:17 < 00:28, 8.55 it/s, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Auc</th>\n",
              "      <th>F1 Minoritaria</th>\n",
              "      <th>F1 Mayoritaria</th>\n",
              "      <th>Prec Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.365959</td>\n",
              "      <td>0.845259</td>\n",
              "      <td>0.842900</td>\n",
              "      <td>0.841702</td>\n",
              "      <td>0.844605</td>\n",
              "      <td>0.844605</td>\n",
              "      <td>0.823649</td>\n",
              "      <td>0.862151</td>\n",
              "      <td>0.747526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.391528</td>\n",
              "      <td>0.855098</td>\n",
              "      <td>0.849150</td>\n",
              "      <td>0.861088</td>\n",
              "      <td>0.843820</td>\n",
              "      <td>0.843820</td>\n",
              "      <td>0.819196</td>\n",
              "      <td>0.879104</td>\n",
              "      <td>0.776712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>0.733442</td>\n",
              "      <td>0.845259</td>\n",
              "      <td>0.843237</td>\n",
              "      <td>0.841770</td>\n",
              "      <td>0.845878</td>\n",
              "      <td>0.845878</td>\n",
              "      <td>0.825429</td>\n",
              "      <td>0.861044</td>\n",
              "      <td>0.746317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.291700</td>\n",
              "      <td>0.887555</td>\n",
              "      <td>0.852415</td>\n",
              "      <td>0.849290</td>\n",
              "      <td>0.849767</td>\n",
              "      <td>0.848848</td>\n",
              "      <td>0.848848</td>\n",
              "      <td>0.827586</td>\n",
              "      <td>0.870993</td>\n",
              "      <td>0.760946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.034700</td>\n",
              "      <td>0.932532</td>\n",
              "      <td>0.855098</td>\n",
              "      <td>0.851501</td>\n",
              "      <td>0.853544</td>\n",
              "      <td>0.849930</td>\n",
              "      <td>0.849930</td>\n",
              "      <td>0.828390</td>\n",
              "      <td>0.874613</td>\n",
              "      <td>0.766980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.034700</td>\n",
              "      <td>1.000490</td>\n",
              "      <td>0.857782</td>\n",
              "      <td>0.854456</td>\n",
              "      <td>0.855855</td>\n",
              "      <td>0.853303</td>\n",
              "      <td>0.853303</td>\n",
              "      <td>0.832455</td>\n",
              "      <td>0.876457</td>\n",
              "      <td>0.770035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>1.029359</td>\n",
              "      <td>0.856887</td>\n",
              "      <td>0.852903</td>\n",
              "      <td>0.856476</td>\n",
              "      <td>0.850482</td>\n",
              "      <td>0.850482</td>\n",
              "      <td>0.828694</td>\n",
              "      <td>0.877112</td>\n",
              "      <td>0.771430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>1.045272</td>\n",
              "      <td>0.855993</td>\n",
              "      <td>0.851663</td>\n",
              "      <td>0.856456</td>\n",
              "      <td>0.848678</td>\n",
              "      <td>0.848678</td>\n",
              "      <td>0.826321</td>\n",
              "      <td>0.877005</td>\n",
              "      <td>0.771438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.057521</td>\n",
              "      <td>0.856887</td>\n",
              "      <td>0.852631</td>\n",
              "      <td>0.857250</td>\n",
              "      <td>0.849718</td>\n",
              "      <td>0.849718</td>\n",
              "      <td>0.827586</td>\n",
              "      <td>0.877676</td>\n",
              "      <td>0.772582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-245\n",
            "Configuration saved in results/checkpoint-245/config.json\n",
            "Model weights saved in results/checkpoint-245/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-245/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-245/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-490\n",
            "Configuration saved in results/checkpoint-490/config.json\n",
            "Model weights saved in results/checkpoint-490/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-490/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-490/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-245] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-735\n",
            "Configuration saved in results/checkpoint-735/config.json\n",
            "Model weights saved in results/checkpoint-735/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-735/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-735/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-980\n",
            "Configuration saved in results/checkpoint-980/config.json\n",
            "Model weights saved in results/checkpoint-980/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-980/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-980/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-1225\n",
            "Configuration saved in results/checkpoint-1225/config.json\n",
            "Model weights saved in results/checkpoint-1225/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1225/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1225/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-735] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-1470\n",
            "Configuration saved in results/checkpoint-1470/config.json\n",
            "Model weights saved in results/checkpoint-1470/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1470/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1470/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-980] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-1715\n",
            "Configuration saved in results/checkpoint-1715/config.json\n",
            "Model weights saved in results/checkpoint-1715/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1715/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1715/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-490] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-1960\n",
            "Configuration saved in results/checkpoint-1960/config.json\n",
            "Model weights saved in results/checkpoint-1960/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1960/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1960/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-1225] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-2205\n",
            "Configuration saved in results/checkpoint-2205/config.json\n",
            "Model weights saved in results/checkpoint-2205/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-2205/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-2205/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-1715] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-1470 (score: 0.8544560462368682).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 11:06:36,045] Trial 2 finished with value: 0.8544560462368682 and parameters: {'per_device_train_batch_size': 16, 'learning_rate': 3e-05, 'weight_decay': 0.1}. Best is trial 0 with value: 0.8627195508977348.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.0004900693893433, 'eval_accuracy': 0.8577817531305904, 'eval_f1': 0.8544560462368682, 'eval_precision': 0.8558547008547008, 'eval_recall': 0.8533030675887818, 'eval_AUC': 0.8533030675887818, 'eval_f1_minoritaria': 0.8324552160168599, 'eval_f1_mayoritaria': 0.8764568764568765, 'eval_PREC_REC': 0.7700348277271354, 'eval_runtime': 1.9648, 'eval_samples_per_second': 569.029, 'eval_steps_per_second': 35.628, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 3912\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1230\n",
            "  Number of trainable parameters = 124644866\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='615' max='1230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 615/1230 02:06 < 02:07, 4.83 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Auc</th>\n",
              "      <th>F1 Minoritaria</th>\n",
              "      <th>F1 Mayoritaria</th>\n",
              "      <th>Prec Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.349127</td>\n",
              "      <td>0.862254</td>\n",
              "      <td>0.854881</td>\n",
              "      <td>0.877072</td>\n",
              "      <td>0.847299</td>\n",
              "      <td>0.847299</td>\n",
              "      <td>0.822171</td>\n",
              "      <td>0.887591</td>\n",
              "      <td>0.796182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.336922</td>\n",
              "      <td>0.865832</td>\n",
              "      <td>0.861842</td>\n",
              "      <td>0.866569</td>\n",
              "      <td>0.858840</td>\n",
              "      <td>0.858840</td>\n",
              "      <td>0.838362</td>\n",
              "      <td>0.885321</td>\n",
              "      <td>0.786085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.538278</td>\n",
              "      <td>0.854204</td>\n",
              "      <td>0.853098</td>\n",
              "      <td>0.852240</td>\n",
              "      <td>0.858819</td>\n",
              "      <td>0.858819</td>\n",
              "      <td>0.840353</td>\n",
              "      <td>0.865844</td>\n",
              "      <td>0.755070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.694157</td>\n",
              "      <td>0.859571</td>\n",
              "      <td>0.854178</td>\n",
              "      <td>0.864357</td>\n",
              "      <td>0.849272</td>\n",
              "      <td>0.849272</td>\n",
              "      <td>0.826135</td>\n",
              "      <td>0.882221</td>\n",
              "      <td>0.782026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.162000</td>\n",
              "      <td>0.792280</td>\n",
              "      <td>0.864043</td>\n",
              "      <td>0.861127</td>\n",
              "      <td>0.861727</td>\n",
              "      <td>0.860580</td>\n",
              "      <td>0.860580</td>\n",
              "      <td>0.841004</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.777978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-123\n",
            "Configuration saved in results/checkpoint-123/config.json\n",
            "Model weights saved in results/checkpoint-123/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-123/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-123/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-1470] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-246\n",
            "Configuration saved in results/checkpoint-246/config.json\n",
            "Model weights saved in results/checkpoint-246/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-246/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-246/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-1960] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-369\n",
            "Configuration saved in results/checkpoint-369/config.json\n",
            "Model weights saved in results/checkpoint-369/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-369/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-369/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-2205] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-492\n",
            "Configuration saved in results/checkpoint-492/config.json\n",
            "Model weights saved in results/checkpoint-492/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-492/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-492/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-123] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-615\n",
            "Configuration saved in results/checkpoint-615/config.json\n",
            "Model weights saved in results/checkpoint-615/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-615/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-615/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-369] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-246 (score: 0.8618415849414742).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 11:08:46,737] Trial 3 finished with value: 0.8618415849414742 and parameters: {'per_device_train_batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.1}. Best is trial 0 with value: 0.8627195508977348.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.33692243695259094, 'eval_accuracy': 0.8658318425760286, 'eval_f1': 0.8618415849414742, 'eval_precision': 0.866568646082344, 'eval_recall': 0.8588400016971445, 'eval_AUC': 0.8588400016971445, 'eval_f1_minoritaria': 0.8383620689655172, 'eval_f1_mayoritaria': 0.8853211009174311, 'eval_PREC_REC': 0.7860854935929074, 'eval_runtime': 1.9697, 'eval_samples_per_second': 567.593, 'eval_steps_per_second': 17.769, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 3912\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1230\n",
            "  Number of trainable parameters = 124644866\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1230' max='1230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1230/1230 04:17, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Auc</th>\n",
              "      <th>F1 Minoritaria</th>\n",
              "      <th>F1 Mayoritaria</th>\n",
              "      <th>Prec Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.470463</td>\n",
              "      <td>0.822898</td>\n",
              "      <td>0.806219</td>\n",
              "      <td>0.864626</td>\n",
              "      <td>0.797488</td>\n",
              "      <td>0.797488</td>\n",
              "      <td>0.749367</td>\n",
              "      <td>0.863071</td>\n",
              "      <td>0.754969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.395861</td>\n",
              "      <td>0.847943</td>\n",
              "      <td>0.844079</td>\n",
              "      <td>0.846357</td>\n",
              "      <td>0.842378</td>\n",
              "      <td>0.842378</td>\n",
              "      <td>0.819533</td>\n",
              "      <td>0.868624</td>\n",
              "      <td>0.756910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.590913</td>\n",
              "      <td>0.849732</td>\n",
              "      <td>0.847672</td>\n",
              "      <td>0.846238</td>\n",
              "      <td>0.850057</td>\n",
              "      <td>0.850057</td>\n",
              "      <td>0.829960</td>\n",
              "      <td>0.865385</td>\n",
              "      <td>0.752816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.746600</td>\n",
              "      <td>0.850626</td>\n",
              "      <td>0.845533</td>\n",
              "      <td>0.852659</td>\n",
              "      <td>0.841678</td>\n",
              "      <td>0.841678</td>\n",
              "      <td>0.817486</td>\n",
              "      <td>0.873581</td>\n",
              "      <td>0.765758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.165800</td>\n",
              "      <td>0.875288</td>\n",
              "      <td>0.852415</td>\n",
              "      <td>0.848443</td>\n",
              "      <td>0.851493</td>\n",
              "      <td>0.846302</td>\n",
              "      <td>0.846302</td>\n",
              "      <td>0.823906</td>\n",
              "      <td>0.872979</td>\n",
              "      <td>0.764278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.165800</td>\n",
              "      <td>0.909504</td>\n",
              "      <td>0.855098</td>\n",
              "      <td>0.851242</td>\n",
              "      <td>0.854160</td>\n",
              "      <td>0.849166</td>\n",
              "      <td>0.849166</td>\n",
              "      <td>0.827292</td>\n",
              "      <td>0.875193</td>\n",
              "      <td>0.768045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.165800</td>\n",
              "      <td>0.943867</td>\n",
              "      <td>0.857782</td>\n",
              "      <td>0.853778</td>\n",
              "      <td>0.857527</td>\n",
              "      <td>0.851266</td>\n",
              "      <td>0.851266</td>\n",
              "      <td>0.829582</td>\n",
              "      <td>0.877974</td>\n",
              "      <td>0.772951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.165800</td>\n",
              "      <td>0.968447</td>\n",
              "      <td>0.857782</td>\n",
              "      <td>0.853506</td>\n",
              "      <td>0.858321</td>\n",
              "      <td>0.850503</td>\n",
              "      <td>0.850503</td>\n",
              "      <td>0.828479</td>\n",
              "      <td>0.878533</td>\n",
              "      <td>0.774119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.981234</td>\n",
              "      <td>0.857782</td>\n",
              "      <td>0.853506</td>\n",
              "      <td>0.858321</td>\n",
              "      <td>0.850503</td>\n",
              "      <td>0.850503</td>\n",
              "      <td>0.828479</td>\n",
              "      <td>0.878533</td>\n",
              "      <td>0.774119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.985580</td>\n",
              "      <td>0.857782</td>\n",
              "      <td>0.853506</td>\n",
              "      <td>0.858321</td>\n",
              "      <td>0.850503</td>\n",
              "      <td>0.850503</td>\n",
              "      <td>0.828479</td>\n",
              "      <td>0.878533</td>\n",
              "      <td>0.774119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-123\n",
            "Configuration saved in results/checkpoint-123/config.json\n",
            "Model weights saved in results/checkpoint-123/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-123/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-123/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-246] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-246\n",
            "Configuration saved in results/checkpoint-246/config.json\n",
            "Model weights saved in results/checkpoint-246/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-246/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-246/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-492] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-369\n",
            "Configuration saved in results/checkpoint-369/config.json\n",
            "Model weights saved in results/checkpoint-369/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-369/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-369/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-615] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-492\n",
            "Configuration saved in results/checkpoint-492/config.json\n",
            "Model weights saved in results/checkpoint-492/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-492/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-492/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-123] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-615\n",
            "Configuration saved in results/checkpoint-615/config.json\n",
            "Model weights saved in results/checkpoint-615/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-615/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-615/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-246] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-738\n",
            "Configuration saved in results/checkpoint-738/config.json\n",
            "Model weights saved in results/checkpoint-738/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-738/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-738/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-369] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-861\n",
            "Configuration saved in results/checkpoint-861/config.json\n",
            "Model weights saved in results/checkpoint-861/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-861/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-861/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-492] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-984\n",
            "Configuration saved in results/checkpoint-984/config.json\n",
            "Model weights saved in results/checkpoint-984/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-984/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-984/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-615] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-1107\n",
            "Configuration saved in results/checkpoint-1107/config.json\n",
            "Model weights saved in results/checkpoint-1107/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1107/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1107/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-738] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-1230\n",
            "Configuration saved in results/checkpoint-1230/config.json\n",
            "Model weights saved in results/checkpoint-1230/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1230/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1230/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-984] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-861 (score: 0.8537779499695237).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 11:13:07,982] Trial 4 finished with value: 0.8537779499695237 and parameters: {'per_device_train_batch_size': 32, 'learning_rate': 5e-05, 'weight_decay': 0.01}. Best is trial 0 with value: 0.8627195508977348.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.9438667893409729, 'eval_accuracy': 0.8577817531305904, 'eval_f1': 0.8537779499695237, 'eval_precision': 0.8575267745621729, 'eval_recall': 0.851266494123637, 'eval_AUC': 0.8512664941236369, 'eval_f1_minoritaria': 0.8295819935691318, 'eval_f1_mayoritaria': 0.8779739063699156, 'eval_PREC_REC': 0.7729505313884816, 'eval_runtime': 1.9495, 'eval_samples_per_second': 573.495, 'eval_steps_per_second': 17.954, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 3912\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2450\n",
            "  Number of trainable parameters = 124644866\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1225' max='2450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1225/2450 02:23 < 02:23, 8.53 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Auc</th>\n",
              "      <th>F1 Minoritaria</th>\n",
              "      <th>F1 Mayoritaria</th>\n",
              "      <th>Prec Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.368515</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.843774</td>\n",
              "      <td>0.842613</td>\n",
              "      <td>0.845390</td>\n",
              "      <td>0.845390</td>\n",
              "      <td>0.824490</td>\n",
              "      <td>0.863057</td>\n",
              "      <td>0.748886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.404258</td>\n",
              "      <td>0.859571</td>\n",
              "      <td>0.852963</td>\n",
              "      <td>0.869631</td>\n",
              "      <td>0.846472</td>\n",
              "      <td>0.846472</td>\n",
              "      <td>0.821793</td>\n",
              "      <td>0.884133</td>\n",
              "      <td>0.787542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.290500</td>\n",
              "      <td>0.683934</td>\n",
              "      <td>0.844365</td>\n",
              "      <td>0.842612</td>\n",
              "      <td>0.841119</td>\n",
              "      <td>0.846111</td>\n",
              "      <td>0.846111</td>\n",
              "      <td>0.826000</td>\n",
              "      <td>0.859223</td>\n",
              "      <td>0.744086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.290500</td>\n",
              "      <td>0.908267</td>\n",
              "      <td>0.849732</td>\n",
              "      <td>0.844556</td>\n",
              "      <td>0.851884</td>\n",
              "      <td>0.840638</td>\n",
              "      <td>0.840638</td>\n",
              "      <td>0.816193</td>\n",
              "      <td>0.872920</td>\n",
              "      <td>0.764614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>0.975670</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.843019</td>\n",
              "      <td>0.843198</td>\n",
              "      <td>0.842844</td>\n",
              "      <td>0.842844</td>\n",
              "      <td>0.820833</td>\n",
              "      <td>0.865204</td>\n",
              "      <td>0.751588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-245\n",
            "Configuration saved in results/checkpoint-245/config.json\n",
            "Model weights saved in results/checkpoint-245/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-245/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-245/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-861] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-490\n",
            "Configuration saved in results/checkpoint-490/config.json\n",
            "Model weights saved in results/checkpoint-490/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-490/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-490/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-1107] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-735\n",
            "Configuration saved in results/checkpoint-735/config.json\n",
            "Model weights saved in results/checkpoint-735/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-735/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-735/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-1230] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-980\n",
            "Configuration saved in results/checkpoint-980/config.json\n",
            "Model weights saved in results/checkpoint-980/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-980/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-980/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-245] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-1225\n",
            "Configuration saved in results/checkpoint-1225/config.json\n",
            "Model weights saved in results/checkpoint-1225/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-1225/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-1225/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-735] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-490 (score: 0.8529631289502453).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 11:15:35,002] Trial 5 finished with value: 0.8529631289502453 and parameters: {'per_device_train_batch_size': 16, 'learning_rate': 3e-05, 'weight_decay': 0.01}. Best is trial 0 with value: 0.8627195508977348.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.40425848960876465, 'eval_accuracy': 0.8595706618962433, 'eval_f1': 0.8529631289502453, 'eval_precision': 0.8696309192200558, 'eval_recall': 0.8464720607577751, 'eval_AUC': 0.846472060757775, 'eval_f1_minoritaria': 0.8217934165720772, 'eval_f1_mayoritaria': 0.8841328413284133, 'eval_PREC_REC': 0.7875419426582217, 'eval_runtime': 1.9747, 'eval_samples_per_second': 566.155, 'eval_steps_per_second': 35.448, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 3912\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1230\n",
            "  Number of trainable parameters = 124644866\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='615' max='1230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 615/1230 02:07 < 02:07, 4.83 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Auc</th>\n",
              "      <th>F1 Minoritaria</th>\n",
              "      <th>F1 Mayoritaria</th>\n",
              "      <th>Prec Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.345393</td>\n",
              "      <td>0.853309</td>\n",
              "      <td>0.845973</td>\n",
              "      <td>0.864757</td>\n",
              "      <td>0.839196</td>\n",
              "      <td>0.839196</td>\n",
              "      <td>0.812357</td>\n",
              "      <td>0.879589</td>\n",
              "      <td>0.779384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.340140</td>\n",
              "      <td>0.865832</td>\n",
              "      <td>0.862422</td>\n",
              "      <td>0.864813</td>\n",
              "      <td>0.860622</td>\n",
              "      <td>0.860622</td>\n",
              "      <td>0.840764</td>\n",
              "      <td>0.884080</td>\n",
              "      <td>0.783232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.459662</td>\n",
              "      <td>0.857782</td>\n",
              "      <td>0.855210</td>\n",
              "      <td>0.854642</td>\n",
              "      <td>0.855849</td>\n",
              "      <td>0.855849</td>\n",
              "      <td>0.835913</td>\n",
              "      <td>0.874507</td>\n",
              "      <td>0.766766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.802904</td>\n",
              "      <td>0.830948</td>\n",
              "      <td>0.829557</td>\n",
              "      <td>0.828634</td>\n",
              "      <td>0.834592</td>\n",
              "      <td>0.834592</td>\n",
              "      <td>0.814159</td>\n",
              "      <td>0.844955</td>\n",
              "      <td>0.724728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.163300</td>\n",
              "      <td>0.894326</td>\n",
              "      <td>0.852415</td>\n",
              "      <td>0.849890</td>\n",
              "      <td>0.849068</td>\n",
              "      <td>0.850885</td>\n",
              "      <td>0.850885</td>\n",
              "      <td>0.830421</td>\n",
              "      <td>0.869359</td>\n",
              "      <td>0.758561</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-123\n",
            "Configuration saved in results/checkpoint-123/config.json\n",
            "Model weights saved in results/checkpoint-123/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-123/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-123/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-490] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-246\n",
            "Configuration saved in results/checkpoint-246/config.json\n",
            "Model weights saved in results/checkpoint-246/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-246/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-246/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-980] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-369\n",
            "Configuration saved in results/checkpoint-369/config.json\n",
            "Model weights saved in results/checkpoint-369/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-369/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-369/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-1225] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-492\n",
            "Configuration saved in results/checkpoint-492/config.json\n",
            "Model weights saved in results/checkpoint-492/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-492/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-492/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-123] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to results/checkpoint-615\n",
            "Configuration saved in results/checkpoint-615/config.json\n",
            "Model weights saved in results/checkpoint-615/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-615/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-615/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-369] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-246 (score: 0.862422351076502).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='35' max='35' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [35/35 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 11:17:45,638] Trial 6 finished with value: 0.862422351076502 and parameters: {'per_device_train_batch_size': 32, 'learning_rate': 5e-05, 'weight_decay': 0.1}. Best is trial 0 with value: 0.8627195508977348.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.34014028310775757, 'eval_accuracy': 0.8658318425760286, 'eval_f1': 0.862422351076502, 'eval_precision': 0.8648131089518187, 'eval_recall': 0.8606220034791463, 'eval_AUC': 0.8606220034791463, 'eval_f1_minoritaria': 0.840764331210191, 'eval_f1_mayoritaria': 0.884080370942813, 'eval_PREC_REC': 0.7832320716092093, 'eval_runtime': 1.9827, 'eval_samples_per_second': 563.878, 'eval_steps_per_second': 17.653, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"PlanTL-GOB-ES/roberta-base-bne\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50262\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/manuelcerrejon/.cache/huggingface/hub/models--PlanTL-GOB-ES--roberta-base-bne/snapshots/0e598176534f3cf2e30105f8286cf2503d6e4731/pytorch_model.bin\n",
            "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 3912\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2450\n",
            "  Number of trainable parameters = 124644866\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='980' max='2450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 980/2450 01:57 < 02:56, 8.31 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Auc</th>\n",
              "      <th>F1 Minoritaria</th>\n",
              "      <th>F1 Mayoritaria</th>\n",
              "      <th>Prec Rec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.389383</td>\n",
              "      <td>0.852415</td>\n",
              "      <td>0.851342</td>\n",
              "      <td>0.850618</td>\n",
              "      <td>0.857249</td>\n",
              "      <td>0.857249</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.863974</td>\n",
              "      <td>0.752456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.451952</td>\n",
              "      <td>0.858676</td>\n",
              "      <td>0.850856</td>\n",
              "      <td>0.874425</td>\n",
              "      <td>0.843141</td>\n",
              "      <td>0.843141</td>\n",
              "      <td>0.816705</td>\n",
              "      <td>0.885007</td>\n",
              "      <td>0.791491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.306800</td>\n",
              "      <td>0.889955</td>\n",
              "      <td>0.813059</td>\n",
              "      <td>0.812807</td>\n",
              "      <td>0.819075</td>\n",
              "      <td>0.823985</td>\n",
              "      <td>0.823985</td>\n",
              "      <td>0.805942</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.699074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.306800</td>\n",
              "      <td>0.717771</td>\n",
              "      <td>0.853309</td>\n",
              "      <td>0.849316</td>\n",
              "      <td>0.852532</td>\n",
              "      <td>0.847087</td>\n",
              "      <td>0.847087</td>\n",
              "      <td>0.824786</td>\n",
              "      <td>0.873846</td>\n",
              "      <td>0.765771</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-245\n",
            "Configuration saved in results/checkpoint-245/config.json\n",
            "Model weights saved in results/checkpoint-245/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-245/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-245/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-246] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-490\n",
            "Configuration saved in results/checkpoint-490/config.json\n",
            "Model weights saved in results/checkpoint-490/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-490/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-490/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-492] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-735\n",
            "Configuration saved in results/checkpoint-735/config.json\n",
            "Model weights saved in results/checkpoint-735/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-735/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-735/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-615] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to results/checkpoint-980\n",
            "Configuration saved in results/checkpoint-980/config.json\n",
            "Model weights saved in results/checkpoint-980/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-980/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-980/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-490] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-245 (score: 0.8513416482727442).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1118\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-16 11:19:46,858] Trial 7 finished with value: 0.8513416482727442 and parameters: {'per_device_train_batch_size': 16, 'learning_rate': 5e-05, 'weight_decay': 0.01}. Best is trial 0 with value: 0.8627195508977348.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3893826901912689, 'eval_accuracy': 0.8524150268336315, 'eval_f1': 0.8513416482727442, 'eval_precision': 0.8506175686756867, 'eval_recall': 0.8572489286775, 'eval_AUC': 0.8572489286775001, 'eval_f1_minoritaria': 0.8387096774193548, 'eval_f1_mayoritaria': 0.8639736191261336, 'eval_PREC_REC': 0.7524555792383819, 'eval_runtime': 1.9826, 'eval_samples_per_second': 563.907, 'eval_steps_per_second': 35.307, 'epoch': 4.0}\n"
          ]
        }
      ],
      "source": [
        "# Realizar la optimización de hiperparámetros\n",
        "study.optimize(compute_objective, n_trials=nbusquedas, callbacks=[partial_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2bg4iDDaNyC",
        "outputId": "4c1a4385-9745-4f69-8b40-bbf2b70ecd30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros: {'per_device_train_batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.01}\n"
          ]
        }
      ],
      "source": [
        "# Imprimir los mejores hiperparámetros encontrados\n",
        "print(\"Mejores hiperparámetros:\", study.best_params)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "043fe75af7434bcaa9915ce3ebe16c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e613eb3a5d4aa8b76ee4a6ecc46dfb",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d288706f524fe2888c14a6de03d662",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "06accd97ad254d5a9afc43309ba91ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08221f205e7c476ea486051cb39d13fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "089aaf939e4b40ff88be45755dd64845": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2f9d6c6e74340078ff89adfafd72135",
              "IPY_MODEL_1681060bf11d474c874db850fcd5d197",
              "IPY_MODEL_1f6b5b8c4db640bda1febf0a83afcfcf"
            ],
            "layout": "IPY_MODEL_0a0e53e5a6664c19803573c891f80ca5"
          }
        },
        "0a0e53e5a6664c19803573c891f80ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab62d2085714b80b1f591bf4ff267fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef432f0fa60842f0bdf57133456db3bb",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_982a2861a18447cdbdd367652c6a87b5",
            "value": 9096718
          }
        },
        "0bf45adaaa6242528683a5b7495dd768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b33092c0cf4a77a732e475a7f219ac",
            "placeholder": "​",
            "style": "IPY_MODEL_e6a588ceb89342789114abb2602437a4",
            "value": "Map: 100%"
          }
        },
        "10556e66bc38414396eb2f08825dfb97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d5513b455146feac21f8e8d2d75370": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5719c4165b564b81b75ac192a7abcd68",
              "IPY_MODEL_9a1b5d1572064740a8930f73a6063ec5",
              "IPY_MODEL_9a5847022353488c830020f36264bd68"
            ],
            "layout": "IPY_MODEL_8bf1f8d41ede4c96afbe812115f8ba10"
          }
        },
        "12db505168ee4d10a763a4b2d6ba6853": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13733d4050b64837abb9295ccfab309d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f0503fe5a141168f9a5a7a56f9433c",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3998113b42904ac886361cdc104525a0",
            "value": 615
          }
        },
        "13822134801245f1a9645315fec1d392": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd5c9dd61c44eb68863cecb0dd97162",
            "placeholder": "​",
            "style": "IPY_MODEL_e9757fe3c528491885f9c87ba3a5d274",
            "value": "tokenizer.json: 100%"
          }
        },
        "1681060bf11d474c874db850fcd5d197": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3b4a2e7d0d84bddabc11a198ee49784",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_526fc67bef94444ca6901ea0e002f12c",
            "value": 400
          }
        },
        "196d29670dad494f9ba8eccfea136748": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b5bb11f9c0545479b54404e5eaef5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d87c1cce342a49f4ac21c06421eb2110",
              "IPY_MODEL_fa838dfed7da4300aab490d6b9cf9659",
              "IPY_MODEL_de8e865d38284203863248a8423f684e"
            ],
            "layout": "IPY_MODEL_1fad39e5458b499c967160adab1e4842"
          }
        },
        "1f6b5b8c4db640bda1febf0a83afcfcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89400a1a138b4ac584853e9a5f959d04",
            "placeholder": "​",
            "style": "IPY_MODEL_c0730f106b8a416db58b9ea5b89cbfbb",
            "value": " 400/400 [00:00&lt;00:00, 4481.86 examples/s]"
          }
        },
        "1fad39e5458b499c967160adab1e4842": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23bc8e346ac34979916adf1878052a27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d4ad5c899054421ac6f3f8dfcf1ed04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3998113b42904ac886361cdc104525a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b61e5b213e24e7092261020348191c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f24e86a5fc451faa2d5d4a66c99848",
            "placeholder": "​",
            "style": "IPY_MODEL_5486aaaf85e542aebc4a86f969bfc1e8",
            "value": "Map: 100%"
          }
        },
        "4bd5c9dd61c44eb68863cecb0dd97162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df159e4f1c54c66952b760835ce00cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_698d1823144043bda14c2e074b55ad03",
              "IPY_MODEL_13733d4050b64837abb9295ccfab309d",
              "IPY_MODEL_d2863650485a4a5ebde49209d531dd75"
            ],
            "layout": "IPY_MODEL_d7eb939ee90c4b02abd85280325bdf89"
          }
        },
        "4e01afcdd48d4515861d53a1a14e0a35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1e87dbf8954b878de9bd2c8361e17d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526fc67bef94444ca6901ea0e002f12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5486aaaf85e542aebc4a86f969bfc1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54eb4a782930414b8a6f442eeb78e3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b61e5b213e24e7092261020348191c7",
              "IPY_MODEL_a288ab582c5f4c6aa2584045fd19ff38",
              "IPY_MODEL_9f03a3c4ddfc4db1b9ecee92b7284865"
            ],
            "layout": "IPY_MODEL_edb4e7063ee142a1bd1d46a78706a546"
          }
        },
        "54f0503fe5a141168f9a5a7a56f9433c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b33092c0cf4a77a732e475a7f219ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56d90fad3faa4fb38ec2da42c9b7416f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1e87dbf8954b878de9bd2c8361e17d",
            "placeholder": "​",
            "style": "IPY_MODEL_9fd55ce7d3714e18ba68a01cdda09a55",
            "value": " 400/400 [00:00&lt;00:00, 8884.36 examples/s]"
          }
        },
        "5719c4165b564b81b75ac192a7abcd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ba0dc34b57741a997758359dbbc1abd",
            "placeholder": "​",
            "style": "IPY_MODEL_fac91a645811443a909ed0bc1e4a2c7b",
            "value": "Map: 100%"
          }
        },
        "6623277ff0944c96b0288617a864c7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6730f6beb6e1481b86687377b48378b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698d1823144043bda14c2e074b55ad03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a01d3f6fb2d4eebaeefe9a293872819",
            "placeholder": "​",
            "style": "IPY_MODEL_196d29670dad494f9ba8eccfea136748",
            "value": "config.json: 100%"
          }
        },
        "6a01d3f6fb2d4eebaeefe9a293872819": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f24e86a5fc451faa2d5d4a66c99848": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784536dd26c649c3b42c1bb09277b326": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c1177cf551b41cfb84276eb4333f8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c08dce0752ec463b82d7a0f9a56339bb",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d951209835ab40e69350b73c9e52caa2",
            "value": 5069051
          }
        },
        "82b1e9dc42014b788216babedfc32228": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13822134801245f1a9645315fec1d392",
              "IPY_MODEL_0ab62d2085714b80b1f591bf4ff267fe",
              "IPY_MODEL_9f74313014de4c9782ec9ea67e616741"
            ],
            "layout": "IPY_MODEL_b00afd73a5fc4682956ce6533f41e2b0"
          }
        },
        "8577cd3673f44958b12b541c55769ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86707ad3a58f4d3d98905940821f2b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89400a1a138b4ac584853e9a5f959d04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b86e2db3c3d4d9b8199cfbfb34ccc3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba0dc34b57741a997758359dbbc1abd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf1f8d41ede4c96afbe812115f8ba10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f82adf939984ef49d272fa3cb8963d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f23834611b4f0e90e205a7d82fdf71",
            "placeholder": "​",
            "style": "IPY_MODEL_86707ad3a58f4d3d98905940821f2b60",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 11.2MB/s]"
          }
        },
        "935ce0134f2a430da156cfc14d082dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecf569392ed34d4aaaa58268deba246a",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad618b76b63d47f290dd8cf7660ac789",
            "value": 400
          }
        },
        "982a2861a18447cdbdd367652c6a87b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a1b5d1572064740a8930f73a6063ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4cae2e052f47c591ccaa21478fbf4c",
            "max": 1600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06accd97ad254d5a9afc43309ba91ab1",
            "value": 1600
          }
        },
        "9a5847022353488c830020f36264bd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08221f205e7c476ea486051cb39d13fa",
            "placeholder": "​",
            "style": "IPY_MODEL_8577cd3673f44958b12b541c55769ec1",
            "value": " 1600/1600 [00:00&lt;00:00, 5697.47 examples/s]"
          }
        },
        "9f03a3c4ddfc4db1b9ecee92b7284865": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6730f6beb6e1481b86687377b48378b2",
            "placeholder": "​",
            "style": "IPY_MODEL_6623277ff0944c96b0288617a864c7a4",
            "value": " 1600/1600 [00:00&lt;00:00, 16162.75 examples/s]"
          }
        },
        "9f74313014de4c9782ec9ea67e616741": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23bc8e346ac34979916adf1878052a27",
            "placeholder": "​",
            "style": "IPY_MODEL_12db505168ee4d10a763a4b2d6ba6853",
            "value": " 9.10M/9.10M [00:00&lt;00:00, 17.2MB/s]"
          }
        },
        "9fd55ce7d3714e18ba68a01cdda09a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a288ab582c5f4c6aa2584045fd19ff38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b86e2db3c3d4d9b8199cfbfb34ccc3f",
            "max": 1600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fee59c728d434b08bb164d41e8e12c17",
            "value": 1600
          }
        },
        "a396650be2ad40efa13a83e5fd9973e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad618b76b63d47f290dd8cf7660ac789": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b00afd73a5fc4682956ce6533f41e2b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f23834611b4f0e90e205a7d82fdf71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0730f106b8a416db58b9ea5b89cbfbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c08dce0752ec463b82d7a0f9a56339bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0e613eb3a5d4aa8b76ee4a6ecc46dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2863650485a4a5ebde49209d531dd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd87348304045d19ff3282b99e9c5df",
            "placeholder": "​",
            "style": "IPY_MODEL_edd76269e67d47bf9fd38ab9afd25e16",
            "value": " 615/615 [00:00&lt;00:00, 38.9kB/s]"
          }
        },
        "d3b4a2e7d0d84bddabc11a198ee49784": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7eb939ee90c4b02abd85280325bdf89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87c1cce342a49f4ac21c06421eb2110": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10556e66bc38414396eb2f08825dfb97",
            "placeholder": "​",
            "style": "IPY_MODEL_2d4ad5c899054421ac6f3f8dfcf1ed04",
            "value": "model.safetensors: 100%"
          }
        },
        "d945728de0fc4f4686adf8ae3920d165": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bf45adaaa6242528683a5b7495dd768",
              "IPY_MODEL_935ce0134f2a430da156cfc14d082dbc",
              "IPY_MODEL_56d90fad3faa4fb38ec2da42c9b7416f"
            ],
            "layout": "IPY_MODEL_a396650be2ad40efa13a83e5fd9973e4"
          }
        },
        "d951209835ab40e69350b73c9e52caa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9d288706f524fe2888c14a6de03d662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de4cae2e052f47c591ccaa21478fbf4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8e865d38284203863248a8423f684e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23d985cf2dc446b9d5391b000988538",
            "placeholder": "​",
            "style": "IPY_MODEL_fe2bbb5b0f6d45e481bb753126b35559",
            "value": " 1.12G/1.12G [00:14&lt;00:00, 33.6MB/s]"
          }
        },
        "e05caf83094841e3b1446c378b7c40d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_043fe75af7434bcaa9915ce3ebe16c89",
              "IPY_MODEL_7c1177cf551b41cfb84276eb4333f8b4",
              "IPY_MODEL_8f82adf939984ef49d272fa3cb8963d0"
            ],
            "layout": "IPY_MODEL_4e01afcdd48d4515861d53a1a14e0a35"
          }
        },
        "e0c10252e3ad4a22bd47f62eff62e406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e23d985cf2dc446b9d5391b000988538": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6a148f5d7534b9bb0a82f771f21b042": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6a588ceb89342789114abb2602437a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9757fe3c528491885f9c87ba3a5d274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecf569392ed34d4aaaa58268deba246a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edb4e7063ee142a1bd1d46a78706a546": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edd76269e67d47bf9fd38ab9afd25e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef05e5efb76941cf9bf43cc0c8f7d1c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef432f0fa60842f0bdf57133456db3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f9d6c6e74340078ff89adfafd72135": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c10252e3ad4a22bd47f62eff62e406",
            "placeholder": "​",
            "style": "IPY_MODEL_e6a148f5d7534b9bb0a82f771f21b042",
            "value": "Map: 100%"
          }
        },
        "fa838dfed7da4300aab490d6b9cf9659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef05e5efb76941cf9bf43cc0c8f7d1c0",
            "max": 1115567652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_784536dd26c649c3b42c1bb09277b326",
            "value": 1115567652
          }
        },
        "fac91a645811443a909ed0bc1e4a2c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbd87348304045d19ff3282b99e9c5df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2bbb5b0f6d45e481bb753126b35559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fee59c728d434b08bb164d41e8e12c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}